---
title: "AGI通用人工智能的下一阶段"
date: 2023-04-23T00:00:00
tags: ['人工智能', '最新资讯', '技术']
author: Frank Lin
category: INSIGHT
---

2022年的Large Language Modle呈现前所未有的超强理解能力和联想创作能力，让世界看到AGI的雏形。2023年科技行业巨头纷纷FOMO，发布自己的大模型，参数越来越大。而开源界则热衷于放出参数量较小的模型，给大模型加上各种能力的Agent以及钻研Prompt Engineering。

由于Agent解决了大模型在计算、记忆和多模态的短板，未来AGI发展的核心依然是大模型，因此本文将论述大模型进一步提升的关键：数据的质量。

**仅凭参数量够大并不能得到涌现**

高质量的数据才能使模型具有更强的泛化能力，而过大的参数量并无法保证质量，且消耗过多的计算资源和训练时间。OpenAI能遥遥领先并不光是参数量够大，有人已经通过各种方式证明GPT-3.5的参数可能只有百亿级。

实现 AGI 需要强大的硬件和计算能力，而短期内由于商业化的考虑，不会集中所有的算力资源来发展更强的GPT大模型，这也对应了OpenAI的山姆奥特曼近期承认的『没有训练GPT-5』一说。据此推断OpenAI只能倾斜算力资源提高数据质量，维持大幅领先优势。

**GPT-4可以帮助提升数据质量**

ShareGPT是由ChatGPT用户共享的聊天数据，已经被许多大模型作为训练数据源，同理通过 GPT-4叠加插件的能力，我们可以将原有的一些数据重新生成，比如搭配Wolfram 生成具有高度逻辑性和实用性的数据。这种数据以往都需要通过人工来进行生成或标注，现在借助GPT-4叠加插件的能力，可以更低成本和高效的数据集。

**新的知识必须具有良好的内在逻辑**

大模型有一个短板就是训练数据无法实时更新，只能分阶段重新训练。因此新知识必须具有较严密的逻辑结构，能够覆盖或淘汰部分旧数据，在保证语义理解能力的同时扩充新的知识。像大部分娱乐类的数据通常并没有太严密的逻辑，只是一些旧数据以随机方式组成并恰好得到人类的喜欢，因此并不需要涵盖在数据集中。

**类 AutoGPT 项目将成为验证手段**

AutoGPT 类项目除了集成Agent，还有着很强的Prompt模板来让生成的数据可以有效提取和循环使用，直到产生出新的知识组合，证明了Prompt Engineering还有巨大的潜力可以挖掘，这也是验证大模型解决实际问题能力的绝佳手段。

**总结**

由于短期内可以用于训练更强大AI的算力资源不足，且现有可训练数据的枯竭可能无法再得到进一步的智能涌现，数据质量将成为进一步提升的关键，相信未来几年不会再以参数量来标榜自家模型的强悍，而是以高能力叠加低成本来论高下。一点浅见，欢迎探讨。